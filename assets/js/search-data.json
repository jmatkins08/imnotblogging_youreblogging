{
  
    
        "post0": {
            "title": "Title",
            "content": "%matplotlib inline %reload_ext autoreload %autoreload 2 . import fastai, timm from fastai.vision.all import * from itertools import compress . path = Path(&#39;/mnt/d/LinuxData/ReconData&#39;) path.is_dir() . True . fastai.__version__, torch.__version__, torch.cuda.is_available() . (&#39;2.7.9&#39;, &#39;1.12.0&#39;, True) . Prepare data for processing . First we pre-process the data to create images without the black area surrounding through a center crop. . path_gst = path/&#39;GST&#39; path_lat = path/&#39;LAT&#39; path_gst.is_dir(), path_lat.is_dir() . (True, True) . gst_fs = get_image_files(path_gst) lat_fs = get_image_files(path_lat) gst_fs[:5], lat_fs[:5] . ((#5) [Path(&#39;/mnt/d/LinuxData/ReconData/GST/ASECLSample2_GST_0040.tif&#39;),Path(&#39;/mnt/d/LinuxData/ReconData/GST/ASECLSample2_GST_0052.tif&#39;),Path(&#39;/mnt/d/LinuxData/ReconData/GST/ASECLSample2_GST_0200.tif&#39;),Path(&#39;/mnt/d/LinuxData/ReconData/GST/ASECLSample2_GST_0201.tif&#39;),Path(&#39;/mnt/d/LinuxData/ReconData/GST/ASECLSample2_GST_0202.tif&#39;)], (#5) [Path(&#39;/mnt/d/LinuxData/ReconData/LAT/ASECLSample2_LAT_0200.tif&#39;),Path(&#39;/mnt/d/LinuxData/ReconData/LAT/ASECLSample2_LAT_0201.tif&#39;),Path(&#39;/mnt/d/LinuxData/ReconData/LAT/ASECLSample2_LAT_0202.tif&#39;),Path(&#39;/mnt/d/LinuxData/ReconData/LAT/ASECLSample2_LAT_0203.tif&#39;),Path(&#39;/mnt/d/LinuxData/ReconData/LAT/ASECLSample2_LAT_0204.tif&#39;)]) . Find the sizes of all the starting images to select the minimum crop size . from fastcore.parallel import * def f(o): return PILImageBW.create(o).size sizes_gst = parallel(f, gst_fs, n_workers=8) sizes_lat = parallel(f, lat_fs, n_workers=8) pd.Series(sizes_gst).value_counts(), pd.Series(sizes_lat).value_counts() . Use 948 as min radius to crop . min_size=int(948/1.4); min_size . 677 . crp_gst = path/&#39;GST_crp&#39; crp_lat = path/&#39;LAT_crp&#39; crp_gst.mkdir(parents=True, exist_ok=True) crp_lat.mkdir(parents=True, exist_ok=True) . def img_resize(o, size=min_size, nparent=Path(&#39;.&#39;)): image = PILImageBW.create(o) h, w = image.size[0] - min_size, image.size[1] - min_size image = image.crop((h//2, w//2, (h//2)+min_size, (w//2)+min_size)) image = image.resize((size, size)) image.save(nparent/(o.stem+&#39;.png&#39;)) return image.size . rz_gst = partial(img_resize, nparent=crp_gst) rz_lat = partial(img_resize, nparent=crp_lat) rz_gst.__module__ = img_resize.__module__ rz_lat.__module__ = img_resize.__module__ rz_gst(gst_fs[0]) . (677, 677) . Create cropped versions of all the images . sizes_gst = parallel(rz_gst, gst_fs, n_workers=8, progress=True) sizes_lat = parallel(rz_lat, lat_fs, n_workers=8, progress=True) pd.Series(sizes_gst).value_counts(), pd.Series(sizes_lat).value_counts() . ((677, 677) 9017 dtype: int64, (677, 677) 9015 dtype: int64) . Create the model . train_sm = df[&#39;small_b&#39;].to_list() . img = PILImageBW.create(train_sm[0]) print(img.size) img.to_thumb(128) . (128, 131) . from fastcore.parallel import * def f(o): return PILImageBW.create(o).size for c in cols: imgs = df[c].to_list() sizes = parallel(f, imgs, n_workers=8) counts = pd.Series(sizes).value_counts() print(c, &#39; n&#39; , counts) . small_g (128, 131) 4209 (128, 130) 2402 (128, 132) 1803 (127, 132) 601 dtype: int64 small_b (128, 131) 4207 (128, 130) 2404 (128, 132) 1803 (127, 132) 601 dtype: int64 mid_g (256, 262) 3005 (256, 261) 2402 (256, 263) 1204 (256, 264) 1202 (256, 265) 601 (255, 264) 601 dtype: int64 mid_b (256, 262) 3606 (256, 261) 2404 (256, 264) 1202 (256, 263) 601 (256, 265) 601 (255, 264) 601 dtype: int64 large_g (256, 262) 3005 (256, 261) 2402 (256, 263) 1204 (256, 264) 1202 (256, 265) 601 (255, 264) 601 dtype: int64 large_b (256, 262) 3606 (256, 261) 2404 (256, 264) 1202 (256, 263) 601 (256, 265) 601 (255, 264) 601 dtype: int64 . Feature Loss . from torchvision.models import vgg16_bn def gram_matrix(x): n,c,h,w = x.size() x = x.view(n, c, -1) return (x @ x.transpose(1,2))/(c*h*w) base_loss = F.l1_loss vgg_m = vgg16_bn(True).features.cuda().eval() for param in vgg_m.parameters(): param.requires_grad = False requires_grad(vgg_m) . /home/juan/mambaforge/envs/fastai/lib/python3.9/site-packages/torchvision/models/_utils.py:135: UserWarning: Using &#39;weights&#39; as positional parameter(s) is deprecated since 0.13 and will be removed in 0.15. Please use keyword parameter(s) instead. warnings.warn( /home/juan/mambaforge/envs/fastai/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for &#39;weights&#39; are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights. warnings.warn(msg) . False . blocks = [i-1 for i,o in enumerate(vgg_m.children()) if isinstance(o, nn.MaxPool2d)] blocks, [vgg_m[i] for i in blocks] . ([5, 12, 22, 32, 42], [ReLU(inplace=True), ReLU(inplace=True), ReLU(inplace=True), ReLU(inplace=True), ReLU(inplace=True)]) . class FeatureLoss(nn.Module): def __init__(self, m_feat, layer_ids, layer_wgts): super().__init__() self.m_feat = m_feat self.loss_features = [self.m_feat[i] for i in layer_ids] self.hooks = hook_outputs(self.loss_features, detach=False) self.wgts = layer_wgts self.metric_names = [&#39;pixel&#39;,] + [f&#39;feat_{i}&#39; for i in range(len(layer_ids))] + [f&#39;gram_{i}&#39; for i in range(len(layer_ids))] def make_features(self, x, clone=False): self.m_feat(x) return [(o.clone() if clone else o) for o in self.hooks.stored] def forward(self, input, target): out_feat = self.make_features(target, clone=True) in_feat = self.make_features(input) self.feat_losses = [base_loss(input, target)] self.feat_losses += [base_loss(f_in, f_out)*w for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)] self.feat_losses += [base_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3 for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)] self.metrics = dict(zip(self.metric_names, self.feat_losses)) return sum(self.feat_losses) def __del__(self): self.hooks.remove() . feat_loss = FeatureLoss(vgg_m, blocks[2:5], [5,15,2]) . Create a data loader . item = Resize(256, method=ResizeMethod.Crop) batch = [*aug_transforms(flip_vert=True, size=128), Normalize()] def get_y(o): return crp_gst/(o.name.replace(&quot;LAT&quot;, &quot;GST&quot;)) . dblock = DataBlock( blocks=(ImageBlock(PILImage), ImageBlock(PILImage)), n_inp=1, get_items=get_image_files, get_y=get_y, splitter=RandomSplitter(valid_pct=0.2), item_tfms=item, batch_tfms=batch, ) . dsets = dblock.datasets(crp_lat) dsets.train[0] . (PILImage mode=RGB size=677x677, PILImage mode=RGB size=677x677) . accum = 2 dls = dblock.dataloaders(crp_lat, bs=64//accum) dls.c = 3 cbs = GradientAccumulation(64) if accum else [] #cbs += [LossMetrics] dls.show_batch(nrows=1, ncols=3) . wd = 1e-3 y_range = (0, 1) learn = unet_learner(dls, resnet50, pretrained=True, wd=wd, loss_func=feat_loss, blur=True, self_attention=True, #norm_type=NormType.Weight, metrics=[mse, mae], #y_range=y_range, #n_in=1, #n_out=1, cbs=cbs, ).to_fp16() . /home/juan/mambaforge/envs/fastai/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter &#39;pretrained&#39; is deprecated since 0.13 and will be removed in 0.15, please use &#39;weights&#39; instead. warnings.warn( /home/juan/mambaforge/envs/fastai/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for &#39;weights&#39; are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights. warnings.warn(msg) . learn.lr_find(suggest_funcs=[minimum, valley], end_lr=1000, num_it=200) . SuggestedLRs(minimum=8.912509656511247e-05, valley=4.46683588961605e-05) . learn.fine_tune(15, base_lr=1e-3, freeze_epochs=3) . epoch train_loss valid_loss mse mae time . 0 | 3.759645 | 3.519774 | 2.185659 | 0.867720 | 10:34 | . 1 | 3.443246 | 3.313853 | 2.086179 | 0.854942 | 09:53 | . 2 | 3.157463 | 2.609716 | 0.801668 | 0.548045 | 10:40 | . epoch train_loss valid_loss mse mae time . 0 | 2.263152 | 1.917143 | 0.201451 | 0.295161 | 09:23 | . 1 | 2.090922 | 1.826157 | 0.168077 | 0.275554 | 09:20 | . 2 | 2.030793 | 1.750588 | 0.153102 | 0.273752 | 09:38 | . 3 | 1.967477 | 1.660006 | 0.128135 | 0.245803 | 09:44 | . 4 | 1.874559 | 1.597451 | 0.108408 | 0.228342 | 08:34 | . 5 | 1.806963 | 1.564758 | 0.130832 | 0.245610 | 08:45 | . 6 | 1.736484 | 1.528925 | 0.102298 | 0.224343 | 09:05 | . 7 | 1.641481 | 1.414897 | 0.081543 | 0.196214 | 10:07 | . 8 | 1.601218 | 1.472612 | 0.106439 | 0.232146 | 08:38 | . 9 | 1.554331 | 1.392800 | 0.083453 | 0.208086 | 09:09 | . 10 | 1.507695 | 1.303817 | 0.066946 | 0.181879 | 08:50 | . 11 | 1.458416 | 1.278669 | 0.062980 | 0.174716 | 09:22 | . 12 | 1.442652 | 1.241596 | 0.054111 | 0.162024 | 09:04 | . 13 | 1.415968 | 1.218767 | 0.052107 | 0.157996 | 09:39 | . 14 | 1.401543 | 1.217585 | 0.051741 | 0.157835 | 09:07 | . learn.show_results() . learn.export(path/&#39;20220825_R50_FL_128.pkl&#39;) . Let&#39;s increase the image size . learn = load_learner(path/&#39;20220825_R50_FL_128.pkl&#39;) . item = Resize(448, method=ResizeMethod.Crop) batch = [*aug_transforms(flip_vert=True, size=224, max_rotate=45.0, min_scale=0.75), Normalize()] dblock = DataBlock( blocks=(ImageBlock(PILImage), ImageBlock(PILImage)), n_inp=1, get_items=get_image_files, get_y=get_y, splitter=RandomSplitter(valid_pct=0.2), item_tfms=item, batch_tfms=batch, ) . accum = 6 dls = dblock.dataloaders(crp_lat, bs=64//accum) dls.c = 3 cbs = GradientAccumulation(64) if accum else [] #cbs += [LossMetrics] dls.show_batch(nrows=1, ncols=3) . learn.dls = dls . learn.lr_find(suggest_funcs=[minimum, valley], end_lr=100, num_it=200) . SuggestedLRs(minimum=6.025595939718187e-05, valley=0.0001273503148695454) . learn.fine_tune(5, base_lr=1e-4, freeze_epochs=3) . epoch train_loss valid_loss mse mae time . 0 | 1.773946 | 1.155278 | 0.143961 | 0.251217 | 43:00 | . 1 | 1.538201 | 1.135846 | 0.133280 | 0.249941 | 42:34 | . 2 | 1.444152 | 1.109244 | 0.128856 | 0.245226 | 41:31 | . epoch train_loss valid_loss mse mae time . 0 | 1.402206 | 1.059702 | 0.111691 | 0.224015 | 41:08 | . 1 | 1.399087 | 1.073283 | 0.117763 | 0.233251 | 41:00 | . 2 | 1.362644 | 1.052603 | 0.109496 | 0.224790 | 40:31 | . 3 | 1.330981 | 1.034533 | 0.110966 | 0.219356 | 40:30 | . 4 | 1.301652 | 1.040552 | 0.110498 | 0.221629 | 40:30 | . learn.show_results() . learn.export(path/&#39;20220825_R50_FL_224.pkl&#39;) .",
            "url": "https://jmatkins08.github.io/imnotblogging_youreblogging/2022/08/25/_Unet_LAT_01.html",
            "relUrl": "/2022/08/25/_Unet_LAT_01.html",
            "date": " • Aug 25, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Using FastAI for Multi-class classification",
            "content": "%matplotlib inline %reload_ext autoreload %autoreload 2 . . import fastai, timm from fastai.vision.all import * from itertools import compress . path = Path(&#39;/mnt/d/ML work/Hackaton&#39;) path.is_dir() . True . fastai.__version__, torch.__version__, torch.cuda.is_available() . (&#39;2.7.9&#39;, &#39;1.12.0&#39;, True) . Create Pandas DataFrame . We create a Pandas DataFrame that summarizes all the files used for the hackaton. . train = (path/&#39;train&#39;).ls() valid = (path/&#39;val&#39;).ls() train_sample = random.sample(train, 200) valid_sample = random.sample(valid, 100) len(train_sample), len(valid_sample) . (200, 100) . We start with a small sample of files to create extraction functions . train_sample[:10] . [Path(&#39;/mnt/d/ML work/Hackaton/train/B005_OD_104_0-0-0-0-0-0-0-0-0.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/A055_OD_51_0-1-0-0-0-0-1-0-1.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/A067_OS_94_0-0-0-0-0-0-0-0-0.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/A097_OS_30_0-0-0-0-1-0-0-0-0.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/C075_OS_31_0-0-0-0-1-0-1-0-0.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/B082_OS_66_0-0-0-0-0-0-0-0-0.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/C038_OD_24_0-0-0-0-0-1-0-0-0.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/C114_OS_46_0-0-1-0-0-0-0-0-0.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/B067_OS_121_0-1-0-0-0-0-1-0-0.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/A014_OD_80_0-0-0-0-1-0-1-0-1.png&#39;)] . cols = [&#39;PatientID&#39;, &#39;Left/Right eye&#39;, &#39;B-Scan ID&#39;, &#39;Labels&#39;] categories = [&#39;Ungradable&#39;, &#39;Intraretinal_Fluid&#39;, &#39;Disturbance_VRI&#39;, &#39;Subretinal_Fluid&#39;, &#39;RPE_Elevation&#39;, &#39;Disruption_Inner_Retinal_Layers&#39;, &#39;Ellipsoid_Zone_Disruption&#39;, &#39;Other_Abnormality&#39;, &#39;RPE_Atrophy&#39;] categories . [&#39;Ungradable&#39;, &#39;Intraretinal_Fluid&#39;, &#39;Disturbance_VRI&#39;, &#39;Subretinal_Fluid&#39;, &#39;RPE_Elevation&#39;, &#39;Disruption_Inner_Retinal_Layers&#39;, &#39;Ellipsoid_Zone_Disruption&#39;, &#39;Other_Abnormality&#39;, &#39;RPE_Atrophy&#39;] . n = valid_sample[5] def path_to_dict(n): info = n.split(&#39;_&#39;) oh_values = [float(i) for i in info[-1].split(&#39;-&#39;)] bool_lab = [bool(i) for i in oh_values] labels = list(compress(categories, bool_lab)) label_str = [&#39;None&#39;] if not labels else [&#39; &#39;.join(labels)] isNone = [1.0] if not labels else [0.0] return dict(zip(cols+categories+[&#39;isNone&#39;], info[:3]+label_str+oh_values+isNone)) def final_dict(n): n_dict = path_to_dict(n.stem) n_dict[&#39;Path&#39;] = n n_dict[&#39;Valid&#39;] = True if n.parent.name == &#39;val&#39; else False return n_dict df_row = final_dict(n) df_row . {&#39;PatientID&#39;: &#39;B036&#39;, &#39;Left/Right eye&#39;: &#39;OS&#39;, &#39;B-Scan ID&#39;: &#39;58&#39;, &#39;Labels&#39;: &#39;None&#39;, &#39;Ungradable&#39;: 0.0, &#39;Intraretinal_Fluid&#39;: 0.0, &#39;Disturbance_VRI&#39;: 0.0, &#39;Subretinal_Fluid&#39;: 0.0, &#39;RPE_Elevation&#39;: 0.0, &#39;Disruption_Inner_Retinal_Layers&#39;: 0.0, &#39;Ellipsoid_Zone_Disruption&#39;: 0.0, &#39;Other_Abnormality&#39;: 0.0, &#39;RPE_Atrophy&#39;: 0.0, &#39;isNone&#39;: 1.0, &#39;Path&#39;: Path(&#39;/mnt/d/ML work/Hackaton/val/B036_OS_58_0-0-0-0-0-0-0-0-0.png&#39;), &#39;Valid&#39;: True} . We can combine lists quickly to create the dictionaries that feed a row in a pandas dataframe. . aux = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;] nums = [&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;] comb = dict(zip(nums, aux[:3] + [&#39;e&#39;])) comb . {&#39;1&#39;: &#39;a&#39;, &#39;2&#39;: &#39;b&#39;, &#39;3&#39;: &#39;c&#39;, &#39;4&#39;: &#39;e&#39;} . a = [&#39;&#39;] not a[0] . True . df_data = pd.DataFrame([final_dict(n) for n in train_sample+valid_sample]) df_data.head() . PatientID Left/Right eye B-Scan ID Labels Ungradable Intraretinal_Fluid Disturbance_VRI Subretinal_Fluid RPE_Elevation Disruption_Inner_Retinal_Layers Ellipsoid_Zone_Disruption Other_Abnormality RPE_Atrophy isNone Path Valid . 0 B005 | OD | 104 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/train/B005_OD_104_0-0-0-0-0-0-0-0-0.png | False | . 1 A055 | OD | 51 | Intraretinal_Fluid Ellipsoid_Zone_Disruption RPE_Atrophy | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 1.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A055_OD_51_0-1-0-0-0-0-1-0-1.png | False | . 2 A067 | OS | 94 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/train/A067_OS_94_0-0-0-0-0-0-0-0-0.png | False | . 3 A097 | OS | 30 | RPE_Elevation | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A097_OS_30_0-0-0-0-1-0-0-0-0.png | False | . 4 C075 | OS | 31 | RPE_Elevation Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/C075_OS_31_0-0-0-0-1-0-1-0-0.png | False | . len(df_data[df_data.isNone==1.0]) . 185 . df_data[&#39;Empty&#39;] = 0 df_data.loc[df_data.isNone==1, &#39;Empty&#39;] = 1 df_data[&#39;Empty&#39;].hist() . &lt;AxesSubplot:&gt; . Now let&#39;s do this to the entire dataset . data = get_image_files(path, folders=[&#39;train&#39;, &#39;val&#39;]) data . (#68992) [Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_0_0-0-0-0-0-0-0-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_100_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_101_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_102_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_103_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_104_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_105_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_106_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_107_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_108_0-0-0-1-0-0-1-0-0.png&#39;)...] . full_data_df = pd.DataFrame([final_dict(n) for n in data]) full_data_df.head() . PatientID Left/Right eye B-Scan ID Labels Ungradable Intraretinal_Fluid Disturbance_VRI Subretinal_Fluid RPE_Elevation Disruption_Inner_Retinal_Layers Ellipsoid_Zone_Disruption Other_Abnormality RPE_Atrophy isNone Path Valid . 0 A001 | OD | 0 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/train/A001_OD_0_0-0-0-0-0-0-0-0-0.png | False | . 1 A001 | OD | 100 | Subretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A001_OD_100_0-0-0-1-0-0-1-0-0.png | False | . 2 A001 | OD | 101 | Subretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A001_OD_101_0-0-0-1-0-0-1-0-0.png | False | . 3 A001 | OD | 102 | Subretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A001_OD_102_0-0-0-1-0-0-1-0-0.png | False | . 4 A001 | OD | 103 | Subretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A001_OD_103_0-0-0-1-0-0-1-0-0.png | False | . full_data_df.isNone.hist() . &lt;AxesSubplot:&gt; . full_data_df.to_pickle(path/&#39;DataList2.pkl&#39;) . From now on we can just reload the saved pickle file. . full_data_df = pd.read_pickle(path/&#39;DataList2.pkl&#39;) full_data_df.head() . PatientID Left/Right eye B-Scan ID Labels Ungradable Intraretinal_Fluid Disturbance_VRI Subretinal_Fluid RPE_Elevation Disruption_Inner_Retinal_Layers Ellipsoid_Zone_Disruption Other_Abnormality RPE_Atrophy isNone Path Valid . 0 A001 | OD | 0 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/train/A001_OD_0_0-0-0-0-0-0-0-0-0.png | False | . 1 A001 | OD | 100 | Subretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A001_OD_100_0-0-0-1-0-0-1-0-0.png | False | . 2 A001 | OD | 101 | Subretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A001_OD_101_0-0-0-1-0-0-1-0-0.png | False | . 3 A001 | OD | 102 | Subretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A001_OD_102_0-0-0-1-0-0-1-0-0.png | False | . 4 A001 | OD | 103 | Subretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A001_OD_103_0-0-0-1-0-0-1-0-0.png | False | . full_data_df[full_data_df[&#39;Valid&#39;]].head() . PatientID Left/Right eye B-Scan ID Labels Ungradable Intraretinal_Fluid Disturbance_VRI Subretinal_Fluid RPE_Elevation Disruption_Inner_Retinal_Layers Ellipsoid_Zone_Disruption Other_Abnormality RPE_Atrophy isNone Path Valid . 61184 A006 | OS | 0 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/val/A006_OS_0_0-0-0-0-0-0-0-0-0.png | True | . 61185 A006 | OS | 100 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/val/A006_OS_100_0-0-0-0-0-0-0-0-0.png | True | . 61186 A006 | OS | 101 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/val/A006_OS_101_0-0-0-0-0-0-0-0-0.png | True | . 61187 A006 | OS | 102 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/val/A006_OS_102_0-0-0-0-0-0-0-0-0.png | True | . 61188 A006 | OS | 103 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/val/A006_OS_103_0-0-0-0-0-0-0-0-0.png | True | . Create the model . Figure out the data shape for all the images. . train[:10] . (#10) [Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_0_0-0-0-0-0-0-0-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_100_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_101_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_102_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_103_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_104_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_105_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_106_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_107_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_108_0-0-0-1-0-0-1-0-0.png&#39;)] . img = PILImageBW.create(train[0]) print(img.size) img.to_thumb(128) . (512, 1024) . from fastcore.parallel import * def f(o): return PILImageBW.create(o).size sizes = parallel(f, train, n_workers=8) pd.Series(sizes).value_counts() . . KeyboardInterrupt Traceback (most recent call last) Input In [21], in &lt;cell line: 4&gt;() 1 from fastcore.parallel import * 3 def f(o): return PILImageBW.create(o).size -&gt; 4 sizes = parallel(f, train, n_workers=8) 5 pd.Series(sizes).value_counts() File ~/mambaforge/envs/fastai/lib/python3.9/site-packages/fastcore/parallel.py:117, in parallel(f, items, n_workers, total, progress, pause, method, threadpool, timeout, chunksize, *args, **kwargs) 115 if total is None: total = len(items) 116 r = progress_bar(r, total=total, leave=False) --&gt; 117 return L(r) File ~/mambaforge/envs/fastai/lib/python3.9/site-packages/fastcore/foundation.py:98, in _L_Meta.__call__(cls, x, *args, **kwargs) 96 def __call__(cls, x=None, *args, **kwargs): 97 if not args and not kwargs and x is not None and isinstance(x,cls): return x &gt; 98 return super().__call__(x, *args, **kwargs) File ~/mambaforge/envs/fastai/lib/python3.9/site-packages/fastcore/foundation.py:106, in L.__init__(self, items, use_list, match, *rest) 104 def __init__(self, items=None, *rest, use_list=False, match=None): 105 if (use_list is not None) or not is_array(items): --&gt; 106 items = listify(items, *rest, use_list=use_list, match=match) 107 super().__init__(items) File ~/mambaforge/envs/fastai/lib/python3.9/site-packages/fastcore/basics.py:63, in listify(o, use_list, match, *rest) 61 elif isinstance(o, list): res = o 62 elif isinstance(o, str) or is_array(o): res = [o] &gt; 63 elif is_iter(o): res = list(o) 64 else: res = [o] 65 if match is not None: File ~/mambaforge/envs/fastai/lib/python3.9/concurrent/futures/process.py:562, in _chain_from_iterable_of_lists(iterable) 556 def _chain_from_iterable_of_lists(iterable): 557 &#34;&#34;&#34; 558 Specialized implementation of itertools.chain.from_iterable. 559 Each item in *iterable* should be a list. This function is 560 careful not to keep references to yielded objects. 561 &#34;&#34;&#34; --&gt; 562 for element in iterable: 563 element.reverse() 564 while element: File ~/mambaforge/envs/fastai/lib/python3.9/concurrent/futures/_base.py:609, in Executor.map.&lt;locals&gt;.result_iterator() 606 while fs: 607 # Careful not to keep a reference to the popped future 608 if timeout is None: --&gt; 609 yield fs.pop().result() 610 else: 611 yield fs.pop().result(end_time - time.monotonic()) File ~/mambaforge/envs/fastai/lib/python3.9/concurrent/futures/_base.py:441, in Future.result(self, timeout) 438 elif self._state == FINISHED: 439 return self.__get_result() --&gt; 441 self._condition.wait(timeout) 443 if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]: 444 raise CancelledError() File ~/mambaforge/envs/fastai/lib/python3.9/threading.py:312, in Condition.wait(self, timeout) 310 try: # restore state no matter what (e.g., KeyboardInterrupt) 311 if timeout is None: --&gt; 312 waiter.acquire() 313 gotit = True 314 else: KeyboardInterrupt: . sizes = parallel(f, valid, n_workers=8) pd.Series(sizes).value_counts() . . Create a data loader . def sample_df(df, pct=0.01): total_imgs = len(df) idx_sample = random.sample(range(total_imgs), int(total_imgs*pct)) small_df = df.iloc[idx_sample].copy() cols = small_df.columns small_df.reset_index(inplace=True) return small_df[cols] . small_df = sample_df(full_data_df) small_df.head() . PatientID Left/Right eye B-Scan ID Labels Ungradable Intraretinal_Fluid Disturbance_VRI Subretinal_Fluid RPE_Elevation Disruption_Inner_Retinal_Layers Ellipsoid_Zone_Disruption Other_Abnormality RPE_Atrophy isNone Path Valid . 0 A122 | OS | 39 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/train/A122_OS_39_0-0-0-0-0-0-0-0-0.png | False | . 1 A096 | OD | 97 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/train/A096_OD_97_0-0-0-0-0-0-0-0-0.png | False | . 2 A198 | OS | 117 | Intraretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A198_OS_117_0-1-0-0-0-0-1-0-0.png | False | . 3 B094 | OD | 67 | RPE_Elevation Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/B094_OD_67_0-0-0-0-1-0-1-0-0.png | False | . 4 C089 | OD | 22 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/train/C089_OD_22_0-0-0-0-0-0-0-0-0.png | False | . def get_x(n): return n[&#39;Path&#39;] def get_y(n): return n[&#39;Labels&#39;].split(&#39; &#39;) def splitter(df): train = df.index[~df[&#39;Valid&#39;]].to_list() # This splitter uses the entire train folder for training valid = df.index[df[&#39;Valid&#39;]].to_list() # This splitter uses the validation folder for validation return train, valid . t, v = splitter(small_df) len(t), len(v), t[:10], v[:10] . (611, 78, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [18, 22, 28, 34, 49, 50, 52, 54, 66, 87]) . size = 128 item = Resize(256, method=ResizeMethod.Pad, pad_mode=PadMode.Reflection) dblock = DataBlock( blocks=(ImageBlock(PILImageBW), MultiCategoryBlock), get_x=get_x, get_y=get_y, splitter=splitter, # RandomSplitter(valid_pct=0.2), item_tfms=item, batch_tfms=aug_transforms(size=size, min_scale=0.75),) . dsets = dblock.datasets(small_df) dsets.train[0] . (PILImageBW mode=L size=512x1024, TensorMultiCategory([0., 0., 0., 0., 1., 0., 0., 0., 0.])) . dls = dblock.dataloaders(small_df, bs=32) dls.show_batch(nrows=1, ncols=3) . arch = &#39;convnext_small_in22k&#39; f1sc = F1ScoreMulti() . def train(arch, size, item=item, accum=1, finetune=True, epochs=5, metrics=partial(accuracy_multi, thres=0.2)): dblock = DataBlock( blocks=(ImageBlock(PILImageBW), MultiCategoryBlock), get_x=get_x, get_y=get_y, splitter=splitter, # RandomSplitter(valid_pct=0.2), item_tfms=item, batch_tfms=aug_transforms(size=size, min_scale=0.75),) dls = dblock.dataloaders(full_data_df, bs=128//accum) cbs = GradientAccumulation(128) if accum else [] learn = vision_learner(dls, arch, metrics=metrics, cbs=cbs).to_fp16() #result = learn.lr_find() if finetune: learn.fine_tune(epochs, 0.01) return learn.tta(), learn else: learn.unfreeze() learn.fit_one_cycle(epochs, 0.01) return learn . val_tta, learn = train(arch, 128, epochs=15, accum=1, finetune=True, metrics=f1sc) . epoch train_loss valid_loss f1_score time . 0 | 0.130614 | 0.166365 | 0.556027 | 10:27 | . epoch train_loss valid_loss f1_score time . 0 | 0.084366 | 0.117138 | 0.648208 | 17:18 | . 1 | 0.069443 | 0.116196 | 0.720429 | 17:19 | . 2 | 0.063303 | 0.113052 | 0.698306 | 17:19 | . 3 | 0.056162 | 0.113664 | 0.720716 | 17:20 | . 4 | 0.050137 | 0.122819 | 0.701130 | 17:18 | . 5 | 0.044736 | 0.124415 | 0.707268 | 17:18 | . 6 | 0.041143 | 0.120144 | 0.707138 | 17:19 | . 7 | 0.037087 | 0.116998 | 0.718447 | 17:19 | . 8 | 0.033376 | 0.120445 | 0.726524 | 17:18 | . 9 | 0.029777 | 0.122809 | 0.728514 | 17:20 | . 10 | 0.025606 | 0.125843 | 0.733744 | 17:18 | . 11 | 0.023641 | 0.132606 | 0.728547 | 17:17 | . 12 | 0.022363 | 0.131488 | 0.713567 | 17:17 | . 13 | 0.022199 | 0.134328 | 0.721964 | 17:17 | . 14 | 0.020537 | 0.133461 | 0.736526 | 17:14 | . . val_tta[0].shape . torch.Size([7808, 10]) . learn.dls.vocab . [&#39;Disruption_Inner_Retinal_Layers&#39;, &#39;Disturbance_VRI&#39;, &#39;Ellipsoid_Zone_Disruption&#39;, &#39;Intraretinal_Fluid&#39;, &#39;None&#39;, &#39;Other_Abnormality&#39;, &#39;RPE_Atrophy&#39;, &#39;RPE_Elevation&#39;, &#39;Subretinal_Fluid&#39;, &#39;Ungradable&#39;] . learn.export(path/&#39;20220815_ConvNext_128px_01.pkl&#39;) . learn = load_learner(path/&#39;20220815_ConvNext_128px_01.pkl&#39;) . item = Resize(512, method=ResizeMethod.Pad, pad_mode=PadMode.Reflection) size = 256 dblock = DataBlock( blocks=(ImageBlock(PILImageBW), MultiCategoryBlock), get_x=get_x, get_y=get_y, splitter=splitter, # RandomSplitter(valid_pct=0.2), item_tfms=item, batch_tfms=aug_transforms(size=size, min_scale=0.75),) def refine_train(arch, size, learner=None, item=item, accum=1, finetune=True, epochs=5, metrics=partial(accuracy_multi, thres=0.2)): dls = dblock.dataloaders(full_data_df, bs=128//accum) cbs = GradientAccumulation(128) if accum else [] learn = ifnone(learner, vision_learner(dls, arch, metrics=metrics, cbs=cbs).to_fp16()) learn.dls = dls if finetune: learn.fine_tune(epochs, 0.01) return learn.tta(), learn else: learn.unfreeze() learn.fit_one_cycle(epochs, 0.01) return _, learn . val_tta256, learn = refine_train(arch, 256, learner=learn, accum=2, metrics=f1sc) . epoch train_loss valid_loss f1_score time . 0 | 0.036489 | 0.116934 | 0.741271 | 35:01 | . epoch train_loss valid_loss f1_score time . 0 | 0.031806 | 0.121453 | 0.759434 | 2:36:13 | . 1 | 0.029942 | 0.116507 | 0.736693 | 2:36:03 | . 2 | 0.022814 | 0.123035 | 0.747249 | 2:35:57 | . 3 | 0.017617 | 0.134090 | 0.736593 | 2:35:57 | . 4 | 0.013542 | 0.129386 | 0.748571 | 2:35:58 | . . learn.export(path/&#39;20220817_ConvNext_256px_01.pkl&#39;) . valid_data = learn.dls.valid . preds, targs = learn.get_preds(dl = valid_data) . preds = tensor(preds&gt;0.5) preds, targs . (tensor([[False, False, False, ..., False, False, False], [False, False, False, ..., False, False, False], [False, False, False, ..., False, False, False], ..., [False, False, False, ..., False, False, False], [False, False, False, ..., False, False, False], [False, False, False, ..., False, False, False]]), tensor([[0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], ..., [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.]])) . f1sc(preds, targs) . 0.7485708693055197 . tta_preds,_ = learn.tta(dl=valid_data) . . tta_preds = tensor(tta_preds&gt;0.5) . f1sc(tta_preds, targs) . 0.750392806526196 . PILBase?? . Init signature: PILBase() Docstring: This class represents an image object. To create :py:class:`~PIL.Image.Image` objects, use the appropriate factory functions. There&#39;s hardly ever any reason to call the Image constructor directly. * :py:func:`~PIL.Image.open` * :py:func:`~PIL.Image.new` * :py:func:`~PIL.Image.frombytes` Source: class PILBase(Image.Image, metaclass=BypassNewMeta): _bypass_type=Image.Image _show_args = {&#39;cmap&#39;:&#39;viridis&#39;} _open_args = {&#39;mode&#39;: &#39;RGB&#39;} @classmethod def create(cls, fn:Path|str|Tensor|ndarray|bytes, **kwargs)-&gt;None: &#34;Open an `Image` from path `fn`&#34; if isinstance(fn,TensorImage): fn = fn.permute(1,2,0).type(torch.uint8) if isinstance(fn, TensorMask): fn = fn.type(torch.uint8) if isinstance(fn,Tensor): fn = fn.numpy() if isinstance(fn,ndarray): return cls(Image.fromarray(fn)) if isinstance(fn,bytes): fn = io.BytesIO(fn) return cls(load_image(fn, **merge(cls._open_args, kwargs))) def show(self, ctx=None, **kwargs): &#34;Show image using `merge(self._show_args, kwargs)`&#34; return show_image(self, ctx=ctx, **merge(self._show_args, kwargs)) def __repr__(self): return f&#39;{self.__class__.__name__} mode={self.mode} size={&#34;x&#34;.join([str(d) for d in self.size])}&#39; File: ~/mambaforge/envs/fastai/lib/python3.9/site-packages/fastai/vision/core.py Type: BypassNewMeta Subclasses: PILImage, PILMask . Verify image integrity . file_list = small_df[&#39;Path&#39;].to_list() img = Image.open(file_list[0]).convert(&#39;L&#39;) img .",
            "url": "https://jmatkins08.github.io/imnotblogging_youreblogging/fastai/jupyter/classification/timm/2022/08/18/Hackaton_01.html",
            "relUrl": "/fastai/jupyter/classification/timm/2022/08/18/Hackaton_01.html",
            "date": " • Aug 18, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://jmatkins08.github.io/imnotblogging_youreblogging/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jmatkins08.github.io/imnotblogging_youreblogging/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}