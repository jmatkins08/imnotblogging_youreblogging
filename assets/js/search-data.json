{
  
    
        "post0": {
            "title": "Using FastAI for Multi-class classification",
            "content": "%matplotlib inline %reload_ext autoreload %autoreload 2 . . import fastai, timm from fastai.vision.all import * from itertools import compress . path = Path(&#39;/mnt/d/ML work/Hackaton&#39;) path.is_dir() . True . fastai.__version__, torch.__version__, torch.cuda.is_available() . (&#39;2.7.9&#39;, &#39;1.12.0&#39;, True) . Create Pandas DataFrame . We create a Pandas DataFrame that summarizes all the files used for the hackaton. . train = (path/&#39;train&#39;).ls() valid = (path/&#39;val&#39;).ls() train_sample = random.sample(train, 200) valid_sample = random.sample(valid, 100) len(train_sample), len(valid_sample) . (200, 100) . We start with a small sample of files to create extraction functions . train_sample[:10] . [Path(&#39;/mnt/d/ML work/Hackaton/train/B005_OD_104_0-0-0-0-0-0-0-0-0.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/A055_OD_51_0-1-0-0-0-0-1-0-1.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/A067_OS_94_0-0-0-0-0-0-0-0-0.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/A097_OS_30_0-0-0-0-1-0-0-0-0.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/C075_OS_31_0-0-0-0-1-0-1-0-0.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/B082_OS_66_0-0-0-0-0-0-0-0-0.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/C038_OD_24_0-0-0-0-0-1-0-0-0.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/C114_OS_46_0-0-1-0-0-0-0-0-0.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/B067_OS_121_0-1-0-0-0-0-1-0-0.png&#39;), Path(&#39;/mnt/d/ML work/Hackaton/train/A014_OD_80_0-0-0-0-1-0-1-0-1.png&#39;)] . cols = [&#39;PatientID&#39;, &#39;Left/Right eye&#39;, &#39;B-Scan ID&#39;, &#39;Labels&#39;] categories = [&#39;Ungradable&#39;, &#39;Intraretinal_Fluid&#39;, &#39;Disturbance_VRI&#39;, &#39;Subretinal_Fluid&#39;, &#39;RPE_Elevation&#39;, &#39;Disruption_Inner_Retinal_Layers&#39;, &#39;Ellipsoid_Zone_Disruption&#39;, &#39;Other_Abnormality&#39;, &#39;RPE_Atrophy&#39;] categories . [&#39;Ungradable&#39;, &#39;Intraretinal_Fluid&#39;, &#39;Disturbance_VRI&#39;, &#39;Subretinal_Fluid&#39;, &#39;RPE_Elevation&#39;, &#39;Disruption_Inner_Retinal_Layers&#39;, &#39;Ellipsoid_Zone_Disruption&#39;, &#39;Other_Abnormality&#39;, &#39;RPE_Atrophy&#39;] . n = valid_sample[5] def path_to_dict(n): info = n.split(&#39;_&#39;) oh_values = [float(i) for i in info[-1].split(&#39;-&#39;)] bool_lab = [bool(i) for i in oh_values] labels = list(compress(categories, bool_lab)) label_str = [&#39;None&#39;] if not labels else [&#39; &#39;.join(labels)] isNone = [1.0] if not labels else [0.0] return dict(zip(cols+categories+[&#39;isNone&#39;], info[:3]+label_str+oh_values+isNone)) def final_dict(n): n_dict = path_to_dict(n.stem) n_dict[&#39;Path&#39;] = n n_dict[&#39;Valid&#39;] = True if n.parent.name == &#39;val&#39; else False return n_dict df_row = final_dict(n) df_row . {&#39;PatientID&#39;: &#39;B036&#39;, &#39;Left/Right eye&#39;: &#39;OS&#39;, &#39;B-Scan ID&#39;: &#39;58&#39;, &#39;Labels&#39;: &#39;None&#39;, &#39;Ungradable&#39;: 0.0, &#39;Intraretinal_Fluid&#39;: 0.0, &#39;Disturbance_VRI&#39;: 0.0, &#39;Subretinal_Fluid&#39;: 0.0, &#39;RPE_Elevation&#39;: 0.0, &#39;Disruption_Inner_Retinal_Layers&#39;: 0.0, &#39;Ellipsoid_Zone_Disruption&#39;: 0.0, &#39;Other_Abnormality&#39;: 0.0, &#39;RPE_Atrophy&#39;: 0.0, &#39;isNone&#39;: 1.0, &#39;Path&#39;: Path(&#39;/mnt/d/ML work/Hackaton/val/B036_OS_58_0-0-0-0-0-0-0-0-0.png&#39;), &#39;Valid&#39;: True} . We can combine lists quickly to create the dictionaries that feed a row in a pandas dataframe. . aux = [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;] nums = [&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;4&#39;] comb = dict(zip(nums, aux[:3] + [&#39;e&#39;])) comb . {&#39;1&#39;: &#39;a&#39;, &#39;2&#39;: &#39;b&#39;, &#39;3&#39;: &#39;c&#39;, &#39;4&#39;: &#39;e&#39;} . a = [&#39;&#39;] not a[0] . True . df_data = pd.DataFrame([final_dict(n) for n in train_sample+valid_sample]) df_data.head() . PatientID Left/Right eye B-Scan ID Labels Ungradable Intraretinal_Fluid Disturbance_VRI Subretinal_Fluid RPE_Elevation Disruption_Inner_Retinal_Layers Ellipsoid_Zone_Disruption Other_Abnormality RPE_Atrophy isNone Path Valid . 0 B005 | OD | 104 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/train/B005_OD_104_0-0-0-0-0-0-0-0-0.png | False | . 1 A055 | OD | 51 | Intraretinal_Fluid Ellipsoid_Zone_Disruption RPE_Atrophy | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 1.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A055_OD_51_0-1-0-0-0-0-1-0-1.png | False | . 2 A067 | OS | 94 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/train/A067_OS_94_0-0-0-0-0-0-0-0-0.png | False | . 3 A097 | OS | 30 | RPE_Elevation | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A097_OS_30_0-0-0-0-1-0-0-0-0.png | False | . 4 C075 | OS | 31 | RPE_Elevation Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/C075_OS_31_0-0-0-0-1-0-1-0-0.png | False | . len(df_data[df_data.isNone==1.0]) . 185 . df_data[&#39;Empty&#39;] = 0 df_data.loc[df_data.isNone==1, &#39;Empty&#39;] = 1 df_data[&#39;Empty&#39;].hist() . &lt;AxesSubplot:&gt; . Now let&#39;s do this to the entire dataset . data = get_image_files(path, folders=[&#39;train&#39;, &#39;val&#39;]) data . (#68992) [Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_0_0-0-0-0-0-0-0-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_100_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_101_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_102_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_103_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_104_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_105_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_106_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_107_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_108_0-0-0-1-0-0-1-0-0.png&#39;)...] . full_data_df = pd.DataFrame([final_dict(n) for n in data]) full_data_df.head() . PatientID Left/Right eye B-Scan ID Labels Ungradable Intraretinal_Fluid Disturbance_VRI Subretinal_Fluid RPE_Elevation Disruption_Inner_Retinal_Layers Ellipsoid_Zone_Disruption Other_Abnormality RPE_Atrophy isNone Path Valid . 0 A001 | OD | 0 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/train/A001_OD_0_0-0-0-0-0-0-0-0-0.png | False | . 1 A001 | OD | 100 | Subretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A001_OD_100_0-0-0-1-0-0-1-0-0.png | False | . 2 A001 | OD | 101 | Subretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A001_OD_101_0-0-0-1-0-0-1-0-0.png | False | . 3 A001 | OD | 102 | Subretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A001_OD_102_0-0-0-1-0-0-1-0-0.png | False | . 4 A001 | OD | 103 | Subretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A001_OD_103_0-0-0-1-0-0-1-0-0.png | False | . full_data_df.isNone.hist() . &lt;AxesSubplot:&gt; . full_data_df.to_pickle(path/&#39;DataList2.pkl&#39;) . From now on we can just reload the saved pickle file. . full_data_df = pd.read_pickle(path/&#39;DataList2.pkl&#39;) full_data_df.head() . PatientID Left/Right eye B-Scan ID Labels Ungradable Intraretinal_Fluid Disturbance_VRI Subretinal_Fluid RPE_Elevation Disruption_Inner_Retinal_Layers Ellipsoid_Zone_Disruption Other_Abnormality RPE_Atrophy isNone Path Valid . 0 A001 | OD | 0 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/train/A001_OD_0_0-0-0-0-0-0-0-0-0.png | False | . 1 A001 | OD | 100 | Subretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A001_OD_100_0-0-0-1-0-0-1-0-0.png | False | . 2 A001 | OD | 101 | Subretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A001_OD_101_0-0-0-1-0-0-1-0-0.png | False | . 3 A001 | OD | 102 | Subretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A001_OD_102_0-0-0-1-0-0-1-0-0.png | False | . 4 A001 | OD | 103 | Subretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A001_OD_103_0-0-0-1-0-0-1-0-0.png | False | . full_data_df[full_data_df[&#39;Valid&#39;]].head() . PatientID Left/Right eye B-Scan ID Labels Ungradable Intraretinal_Fluid Disturbance_VRI Subretinal_Fluid RPE_Elevation Disruption_Inner_Retinal_Layers Ellipsoid_Zone_Disruption Other_Abnormality RPE_Atrophy isNone Path Valid . 61184 A006 | OS | 0 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/val/A006_OS_0_0-0-0-0-0-0-0-0-0.png | True | . 61185 A006 | OS | 100 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/val/A006_OS_100_0-0-0-0-0-0-0-0-0.png | True | . 61186 A006 | OS | 101 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/val/A006_OS_101_0-0-0-0-0-0-0-0-0.png | True | . 61187 A006 | OS | 102 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/val/A006_OS_102_0-0-0-0-0-0-0-0-0.png | True | . 61188 A006 | OS | 103 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/val/A006_OS_103_0-0-0-0-0-0-0-0-0.png | True | . Create the model . Figure out the data shape for all the images. . train[:10] . (#10) [Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_0_0-0-0-0-0-0-0-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_100_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_101_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_102_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_103_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_104_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_105_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_106_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_107_0-0-0-1-0-0-1-0-0.png&#39;),Path(&#39;/mnt/d/ML work/Hackaton/train/A001_OD_108_0-0-0-1-0-0-1-0-0.png&#39;)] . img = PILImageBW.create(train[0]) print(img.size) img.to_thumb(128) . (512, 1024) . from fastcore.parallel import * def f(o): return PILImageBW.create(o).size sizes = parallel(f, train, n_workers=8) pd.Series(sizes).value_counts() . . KeyboardInterrupt Traceback (most recent call last) Input In [21], in &lt;cell line: 4&gt;() 1 from fastcore.parallel import * 3 def f(o): return PILImageBW.create(o).size -&gt; 4 sizes = parallel(f, train, n_workers=8) 5 pd.Series(sizes).value_counts() File ~/mambaforge/envs/fastai/lib/python3.9/site-packages/fastcore/parallel.py:117, in parallel(f, items, n_workers, total, progress, pause, method, threadpool, timeout, chunksize, *args, **kwargs) 115 if total is None: total = len(items) 116 r = progress_bar(r, total=total, leave=False) --&gt; 117 return L(r) File ~/mambaforge/envs/fastai/lib/python3.9/site-packages/fastcore/foundation.py:98, in _L_Meta.__call__(cls, x, *args, **kwargs) 96 def __call__(cls, x=None, *args, **kwargs): 97 if not args and not kwargs and x is not None and isinstance(x,cls): return x &gt; 98 return super().__call__(x, *args, **kwargs) File ~/mambaforge/envs/fastai/lib/python3.9/site-packages/fastcore/foundation.py:106, in L.__init__(self, items, use_list, match, *rest) 104 def __init__(self, items=None, *rest, use_list=False, match=None): 105 if (use_list is not None) or not is_array(items): --&gt; 106 items = listify(items, *rest, use_list=use_list, match=match) 107 super().__init__(items) File ~/mambaforge/envs/fastai/lib/python3.9/site-packages/fastcore/basics.py:63, in listify(o, use_list, match, *rest) 61 elif isinstance(o, list): res = o 62 elif isinstance(o, str) or is_array(o): res = [o] &gt; 63 elif is_iter(o): res = list(o) 64 else: res = [o] 65 if match is not None: File ~/mambaforge/envs/fastai/lib/python3.9/concurrent/futures/process.py:562, in _chain_from_iterable_of_lists(iterable) 556 def _chain_from_iterable_of_lists(iterable): 557 &#34;&#34;&#34; 558 Specialized implementation of itertools.chain.from_iterable. 559 Each item in *iterable* should be a list. This function is 560 careful not to keep references to yielded objects. 561 &#34;&#34;&#34; --&gt; 562 for element in iterable: 563 element.reverse() 564 while element: File ~/mambaforge/envs/fastai/lib/python3.9/concurrent/futures/_base.py:609, in Executor.map.&lt;locals&gt;.result_iterator() 606 while fs: 607 # Careful not to keep a reference to the popped future 608 if timeout is None: --&gt; 609 yield fs.pop().result() 610 else: 611 yield fs.pop().result(end_time - time.monotonic()) File ~/mambaforge/envs/fastai/lib/python3.9/concurrent/futures/_base.py:441, in Future.result(self, timeout) 438 elif self._state == FINISHED: 439 return self.__get_result() --&gt; 441 self._condition.wait(timeout) 443 if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]: 444 raise CancelledError() File ~/mambaforge/envs/fastai/lib/python3.9/threading.py:312, in Condition.wait(self, timeout) 310 try: # restore state no matter what (e.g., KeyboardInterrupt) 311 if timeout is None: --&gt; 312 waiter.acquire() 313 gotit = True 314 else: KeyboardInterrupt: . sizes = parallel(f, valid, n_workers=8) pd.Series(sizes).value_counts() . . Create a data loader . def sample_df(df, pct=0.01): total_imgs = len(df) idx_sample = random.sample(range(total_imgs), int(total_imgs*pct)) small_df = df.iloc[idx_sample].copy() cols = small_df.columns small_df.reset_index(inplace=True) return small_df[cols] . small_df = sample_df(full_data_df) small_df.head() . PatientID Left/Right eye B-Scan ID Labels Ungradable Intraretinal_Fluid Disturbance_VRI Subretinal_Fluid RPE_Elevation Disruption_Inner_Retinal_Layers Ellipsoid_Zone_Disruption Other_Abnormality RPE_Atrophy isNone Path Valid . 0 A122 | OS | 39 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/train/A122_OS_39_0-0-0-0-0-0-0-0-0.png | False | . 1 A096 | OD | 97 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/train/A096_OD_97_0-0-0-0-0-0-0-0-0.png | False | . 2 A198 | OS | 117 | Intraretinal_Fluid Ellipsoid_Zone_Disruption | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/A198_OS_117_0-1-0-0-0-0-1-0-0.png | False | . 3 B094 | OD | 67 | RPE_Elevation Ellipsoid_Zone_Disruption | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | /mnt/d/ML work/Hackaton/train/B094_OD_67_0-0-0-0-1-0-1-0-0.png | False | . 4 C089 | OD | 22 | None | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | /mnt/d/ML work/Hackaton/train/C089_OD_22_0-0-0-0-0-0-0-0-0.png | False | . def get_x(n): return n[&#39;Path&#39;] def get_y(n): return n[&#39;Labels&#39;].split(&#39; &#39;) def splitter(df): train = df.index[~df[&#39;Valid&#39;]].to_list() # This splitter uses the entire train folder for training valid = df.index[df[&#39;Valid&#39;]].to_list() # This splitter uses the validation folder for validation return train, valid . t, v = splitter(small_df) len(t), len(v), t[:10], v[:10] . (611, 78, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9], [18, 22, 28, 34, 49, 50, 52, 54, 66, 87]) . size = 128 item = Resize(256, method=ResizeMethod.Pad, pad_mode=PadMode.Reflection) dblock = DataBlock( blocks=(ImageBlock(PILImageBW), MultiCategoryBlock), get_x=get_x, get_y=get_y, splitter=splitter, # RandomSplitter(valid_pct=0.2), item_tfms=item, batch_tfms=aug_transforms(size=size, min_scale=0.75),) . dsets = dblock.datasets(small_df) dsets.train[0] . (PILImageBW mode=L size=512x1024, TensorMultiCategory([0., 0., 0., 0., 1., 0., 0., 0., 0.])) . dls = dblock.dataloaders(small_df, bs=32) dls.show_batch(nrows=1, ncols=3) . arch = &#39;convnext_small_in22k&#39; f1sc = F1ScoreMulti() . def train(arch, size, item=item, accum=1, finetune=True, epochs=5, metrics=partial(accuracy_multi, thres=0.2)): dblock = DataBlock( blocks=(ImageBlock(PILImageBW), MultiCategoryBlock), get_x=get_x, get_y=get_y, splitter=splitter, # RandomSplitter(valid_pct=0.2), item_tfms=item, batch_tfms=aug_transforms(size=size, min_scale=0.75),) dls = dblock.dataloaders(full_data_df, bs=128//accum) cbs = GradientAccumulation(128) if accum else [] learn = vision_learner(dls, arch, metrics=metrics, cbs=cbs).to_fp16() #result = learn.lr_find() if finetune: learn.fine_tune(epochs, 0.01) return learn.tta(), learn else: learn.unfreeze() learn.fit_one_cycle(epochs, 0.01) return learn . val_tta, learn = train(arch, 128, epochs=15, accum=1, finetune=True, metrics=f1sc) . epoch train_loss valid_loss f1_score time . 0 | 0.130614 | 0.166365 | 0.556027 | 10:27 | . epoch train_loss valid_loss f1_score time . 0 | 0.084366 | 0.117138 | 0.648208 | 17:18 | . 1 | 0.069443 | 0.116196 | 0.720429 | 17:19 | . 2 | 0.063303 | 0.113052 | 0.698306 | 17:19 | . 3 | 0.056162 | 0.113664 | 0.720716 | 17:20 | . 4 | 0.050137 | 0.122819 | 0.701130 | 17:18 | . 5 | 0.044736 | 0.124415 | 0.707268 | 17:18 | . 6 | 0.041143 | 0.120144 | 0.707138 | 17:19 | . 7 | 0.037087 | 0.116998 | 0.718447 | 17:19 | . 8 | 0.033376 | 0.120445 | 0.726524 | 17:18 | . 9 | 0.029777 | 0.122809 | 0.728514 | 17:20 | . 10 | 0.025606 | 0.125843 | 0.733744 | 17:18 | . 11 | 0.023641 | 0.132606 | 0.728547 | 17:17 | . 12 | 0.022363 | 0.131488 | 0.713567 | 17:17 | . 13 | 0.022199 | 0.134328 | 0.721964 | 17:17 | . 14 | 0.020537 | 0.133461 | 0.736526 | 17:14 | . . val_tta[0].shape . torch.Size([7808, 10]) . learn.dls.vocab . [&#39;Disruption_Inner_Retinal_Layers&#39;, &#39;Disturbance_VRI&#39;, &#39;Ellipsoid_Zone_Disruption&#39;, &#39;Intraretinal_Fluid&#39;, &#39;None&#39;, &#39;Other_Abnormality&#39;, &#39;RPE_Atrophy&#39;, &#39;RPE_Elevation&#39;, &#39;Subretinal_Fluid&#39;, &#39;Ungradable&#39;] . learn.export(path/&#39;20220815_ConvNext_128px_01.pkl&#39;) . learn = load_learner(path/&#39;20220815_ConvNext_128px_01.pkl&#39;) . item = Resize(512, method=ResizeMethod.Pad, pad_mode=PadMode.Reflection) size = 256 dblock = DataBlock( blocks=(ImageBlock(PILImageBW), MultiCategoryBlock), get_x=get_x, get_y=get_y, splitter=splitter, # RandomSplitter(valid_pct=0.2), item_tfms=item, batch_tfms=aug_transforms(size=size, min_scale=0.75),) def refine_train(arch, size, learner=None, item=item, accum=1, finetune=True, epochs=5, metrics=partial(accuracy_multi, thres=0.2)): dls = dblock.dataloaders(full_data_df, bs=128//accum) cbs = GradientAccumulation(128) if accum else [] learn = ifnone(learner, vision_learner(dls, arch, metrics=metrics, cbs=cbs).to_fp16()) learn.dls = dls if finetune: learn.fine_tune(epochs, 0.01) return learn.tta(), learn else: learn.unfreeze() learn.fit_one_cycle(epochs, 0.01) return _, learn . val_tta256, learn = refine_train(arch, 256, learner=learn, accum=2, metrics=f1sc) . epoch train_loss valid_loss f1_score time . 0 | 0.036489 | 0.116934 | 0.741271 | 35:01 | . epoch train_loss valid_loss f1_score time . 0 | 0.031806 | 0.121453 | 0.759434 | 2:36:13 | . 1 | 0.029942 | 0.116507 | 0.736693 | 2:36:03 | . 2 | 0.022814 | 0.123035 | 0.747249 | 2:35:57 | . 3 | 0.017617 | 0.134090 | 0.736593 | 2:35:57 | . 4 | 0.013542 | 0.129386 | 0.748571 | 2:35:58 | . . learn.export(path/&#39;20220817_ConvNext_256px_01.pkl&#39;) . valid_data = learn.dls.valid . preds, targs = learn.get_preds(dl = valid_data) . preds = tensor(preds&gt;0.5) preds, targs . (tensor([[False, False, False, ..., False, False, False], [False, False, False, ..., False, False, False], [False, False, False, ..., False, False, False], ..., [False, False, False, ..., False, False, False], [False, False, False, ..., False, False, False], [False, False, False, ..., False, False, False]]), tensor([[0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], ..., [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.]])) . f1sc(preds, targs) . 0.7485708693055197 . tta_preds,_ = learn.tta(dl=valid_data) . . tta_preds = tensor(tta_preds&gt;0.5) . f1sc(tta_preds, targs) . 0.750392806526196 . PILBase?? . Init signature: PILBase() Docstring: This class represents an image object. To create :py:class:`~PIL.Image.Image` objects, use the appropriate factory functions. There&#39;s hardly ever any reason to call the Image constructor directly. * :py:func:`~PIL.Image.open` * :py:func:`~PIL.Image.new` * :py:func:`~PIL.Image.frombytes` Source: class PILBase(Image.Image, metaclass=BypassNewMeta): _bypass_type=Image.Image _show_args = {&#39;cmap&#39;:&#39;viridis&#39;} _open_args = {&#39;mode&#39;: &#39;RGB&#39;} @classmethod def create(cls, fn:Path|str|Tensor|ndarray|bytes, **kwargs)-&gt;None: &#34;Open an `Image` from path `fn`&#34; if isinstance(fn,TensorImage): fn = fn.permute(1,2,0).type(torch.uint8) if isinstance(fn, TensorMask): fn = fn.type(torch.uint8) if isinstance(fn,Tensor): fn = fn.numpy() if isinstance(fn,ndarray): return cls(Image.fromarray(fn)) if isinstance(fn,bytes): fn = io.BytesIO(fn) return cls(load_image(fn, **merge(cls._open_args, kwargs))) def show(self, ctx=None, **kwargs): &#34;Show image using `merge(self._show_args, kwargs)`&#34; return show_image(self, ctx=ctx, **merge(self._show_args, kwargs)) def __repr__(self): return f&#39;{self.__class__.__name__} mode={self.mode} size={&#34;x&#34;.join([str(d) for d in self.size])}&#39; File: ~/mambaforge/envs/fastai/lib/python3.9/site-packages/fastai/vision/core.py Type: BypassNewMeta Subclasses: PILImage, PILMask . Verify image integrity . file_list = small_df[&#39;Path&#39;].to_list() img = Image.open(file_list[0]).convert(&#39;L&#39;) img .",
            "url": "https://jmatkins08.github.io/imnotblogging_youreblogging/fastai/jupyter/classification/timm/2022/08/18/Hackaton_01.html",
            "relUrl": "/fastai/jupyter/classification/timm/2022/08/18/Hackaton_01.html",
            "date": " • Aug 18, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://jmatkins08.github.io/imnotblogging_youreblogging/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jmatkins08.github.io/imnotblogging_youreblogging/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}